{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76a98bf-682c-40fb-b376-1b2288981d29",
   "metadata": {},
   "source": [
    "<font face=\"Times\" size=13 color=#A52A2A >\n",
    "Fetch - Data Analyst Take Home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040b404d-74fa-4aa3-9271-eb0f0c7ce4d7",
   "metadata": {},
   "source": [
    "<font face=\"Times\" size=4 color=#121211 >\n",
    "    Name: JieXin Chen\n",
    "    <br>January 22, 2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4652dc78-8bac-4965-a0fe-b4c9ec14e5cb",
   "metadata": {},
   "source": [
    "In my analysis process, I import CSV files into Excel for closer inspection. Excel's filter function is helpful for quickly identifying empty values or anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "3fc2ec59-195a-43e0-88de-bb26e82d7abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbb90a-0c0d-4243-956a-883f6cb358ef",
   "metadata": {},
   "source": [
    "# Step 1: Load the datasets \n",
    "\n",
    "In this step, I will load the provided CSV files into Python using pandas. This allows me to structure the data into DataFrames for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ad99fb7f-adad-42aa-8536-8e5eaba53247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Users, Products, and Transactions dataset\n",
    "users_path = \"/Users/jc/Desktop/xing/fetch/interview/USER_TAKEHOME.csv\"  \n",
    "transactions_path = \"/Users/jc/Desktop/xing/fetch/interview/TRANSACTION_TAKEHOME.csv\" \n",
    "products_path = \"/Users/jc/Desktop/xing/fetch/interview/PRODUCTS_TAKEHOME.csv\" \n",
    "\n",
    "# Load data into pandas DataFrames\n",
    "users_df = pd.read_csv(users_path, dtype=str)\n",
    "transactions_df = pd.read_csv(transactions_path, dtype=str)\n",
    "products_df = pd.read_csv(products_path, dtype=str, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38b33c-de5d-47ac-a272-0092f33f7fba",
   "metadata": {},
   "source": [
    "# Step 2: Overview of each dataset\n",
    "\n",
    "I will inspect the first few rows of each dataset to get an overview of the data structure. This helps me understand the data type in each column and identify any immediate issues, such as unexpected formats or missing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5005875e-3c89-4843-9bc4-3b753116a052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ef3b4f17053ab141787697d</td>\n",
       "      <td>2020-06-24 20:17:54.000 Z</td>\n",
       "      <td>2000-08-11 00:00:00.000 Z</td>\n",
       "      <td>CA</td>\n",
       "      <td>es-419</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ff220d383fcfc12622b96bc</td>\n",
       "      <td>2021-01-03 19:53:55.000 Z</td>\n",
       "      <td>2001-09-24 04:00:00.000 Z</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6477950aa55bb77a0e27ee10</td>\n",
       "      <td>2023-05-31 18:42:18.000 Z</td>\n",
       "      <td>1994-10-28 00:00:00.000 Z</td>\n",
       "      <td>FL</td>\n",
       "      <td>es-419</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>658a306e99b40f103b63ccf8</td>\n",
       "      <td>2023-12-26 01:46:22.000 Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NC</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>653cf5d6a225ea102b7ecdc2</td>\n",
       "      <td>2023-10-28 11:51:50.000 Z</td>\n",
       "      <td>1972-03-19 00:00:00.000 Z</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID               CREATED_DATE  \\\n",
       "0  5ef3b4f17053ab141787697d  2020-06-24 20:17:54.000 Z   \n",
       "1  5ff220d383fcfc12622b96bc  2021-01-03 19:53:55.000 Z   \n",
       "2  6477950aa55bb77a0e27ee10  2023-05-31 18:42:18.000 Z   \n",
       "3  658a306e99b40f103b63ccf8  2023-12-26 01:46:22.000 Z   \n",
       "4  653cf5d6a225ea102b7ecdc2  2023-10-28 11:51:50.000 Z   \n",
       "\n",
       "                  BIRTH_DATE STATE LANGUAGE  GENDER  \n",
       "0  2000-08-11 00:00:00.000 Z    CA   es-419  female  \n",
       "1  2001-09-24 04:00:00.000 Z    PA       en  female  \n",
       "2  1994-10-28 00:00:00.000 Z    FL   es-419  female  \n",
       "3                        NaN    NC       en     NaN  \n",
       "4  1972-03-19 00:00:00.000 Z    PA       en  female  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Users Dataset:\")\n",
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c35ccede-593f-48b8-badf-5c13b5aca83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d256-4041-4a3e-adc4-5623fb6e0c99</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>2024-08-21 14:19:06.539 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>63b73a7f3d310dceeabd4758</td>\n",
       "      <td>015300014978</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001455d-7a92-4a7b-a1d2-c747af1c8fd3</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>2024-07-20 09:50:24.206 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>62c08877baa38d1a1f6c211a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017e0a-7851-42fb-bfab-0baa96e23586</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>2024-08-19 15:38:56.813 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>60842f207ac8b7729e472020</td>\n",
       "      <td>078742229751</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000239aa-3478-453d-801e-66a82e39c8af</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-19 11:03:37.468 Z</td>\n",
       "      <td>FOOD LION</td>\n",
       "      <td>63fcd7cea4f8442c3386b589</td>\n",
       "      <td>783399746536</td>\n",
       "      <td>zero</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-05 15:56:43.549 Z</td>\n",
       "      <td>RANDALLS</td>\n",
       "      <td>6193231ae9b3d75037b0f928</td>\n",
       "      <td>047900501183</td>\n",
       "      <td>1.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RECEIPT_ID PURCHASE_DATE  \\\n",
       "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
       "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
       "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
       "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
       "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
       "\n",
       "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
       "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
       "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
       "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
       "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
       "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
       "\n",
       "        BARCODE FINAL_QUANTITY FINAL_SALE  \n",
       "0  015300014978           1.00             \n",
       "1           NaN           zero       1.49  \n",
       "2  078742229751           1.00             \n",
       "3  783399746536           zero       3.49  \n",
       "4  047900501183           1.00             "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Transactions Dataset:\")\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c277d42-850c-4d7c-8930-5133ee002775",
   "metadata": {},
   "source": [
    "Based on the dataset, I identified an issue in the FINAL_SALE column where some values were blank or invalid. Since this column is expected to contain numerical data representing sales values, such inconsistencies needed to be addressed. To resolve this, I used the pd.to_numeric() function to convert the FINAL_SALE column into a numeric data type. This method automatically converted invalid entries into NaN, allowing them to be appropriately treated as missing values during further analysis or imputation. This ensures the column is now clean and ready for numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "04a14225-6b42-4030-a712-8a7cf70f5675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Convert the FINAL_SALE column to numeric, coercing invalid entries to NaN\n",
    "transactions_df['FINAL_SALE'] = pd.to_numeric(transactions_df['FINAL_SALE'], errors='coerce')\n",
    "\n",
    "# Check the data type of the FINAL_SALE column\n",
    "print(transactions_df['FINAL_SALE'].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d562e003-d109-4b3a-96a4-8d1bcf227a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d256-4041-4a3e-adc4-5623fb6e0c99</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>2024-08-21 14:19:06.539 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>63b73a7f3d310dceeabd4758</td>\n",
       "      <td>015300014978</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001455d-7a92-4a7b-a1d2-c747af1c8fd3</td>\n",
       "      <td>2024-07-20</td>\n",
       "      <td>2024-07-20 09:50:24.206 Z</td>\n",
       "      <td>ALDI</td>\n",
       "      <td>62c08877baa38d1a1f6c211a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zero</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017e0a-7851-42fb-bfab-0baa96e23586</td>\n",
       "      <td>2024-08-18</td>\n",
       "      <td>2024-08-19 15:38:56.813 Z</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>60842f207ac8b7729e472020</td>\n",
       "      <td>078742229751</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000239aa-3478-453d-801e-66a82e39c8af</td>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>2024-06-19 11:03:37.468 Z</td>\n",
       "      <td>FOOD LION</td>\n",
       "      <td>63fcd7cea4f8442c3386b589</td>\n",
       "      <td>783399746536</td>\n",
       "      <td>zero</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1</td>\n",
       "      <td>2024-07-04</td>\n",
       "      <td>2024-07-05 15:56:43.549 Z</td>\n",
       "      <td>RANDALLS</td>\n",
       "      <td>6193231ae9b3d75037b0f928</td>\n",
       "      <td>047900501183</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             RECEIPT_ID PURCHASE_DATE  \\\n",
       "0  0000d256-4041-4a3e-adc4-5623fb6e0c99    2024-08-21   \n",
       "1  0001455d-7a92-4a7b-a1d2-c747af1c8fd3    2024-07-20   \n",
       "2  00017e0a-7851-42fb-bfab-0baa96e23586    2024-08-18   \n",
       "3  000239aa-3478-453d-801e-66a82e39c8af    2024-06-18   \n",
       "4  00026b4c-dfe8-49dd-b026-4c2f0fd5c6a1    2024-07-04   \n",
       "\n",
       "                   SCAN_DATE STORE_NAME                   USER_ID  \\\n",
       "0  2024-08-21 14:19:06.539 Z    WALMART  63b73a7f3d310dceeabd4758   \n",
       "1  2024-07-20 09:50:24.206 Z       ALDI  62c08877baa38d1a1f6c211a   \n",
       "2  2024-08-19 15:38:56.813 Z    WALMART  60842f207ac8b7729e472020   \n",
       "3  2024-06-19 11:03:37.468 Z  FOOD LION  63fcd7cea4f8442c3386b589   \n",
       "4  2024-07-05 15:56:43.549 Z   RANDALLS  6193231ae9b3d75037b0f928   \n",
       "\n",
       "        BARCODE FINAL_QUANTITY  FINAL_SALE  \n",
       "0  015300014978           1.00         NaN  \n",
       "1           NaN           zero        1.49  \n",
       "2  078742229751           1.00         NaN  \n",
       "3  783399746536           zero        3.49  \n",
       "4  047900501183           1.00         NaN  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the transactions dataset again to verify changes\n",
    "# Ensures that the 'FINAL_SALE' column has been successfully converted to numeric\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "11e9b64e-65d4-4452-a124-3c7288488668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY_1</th>\n",
       "      <th>CATEGORY_2</th>\n",
       "      <th>CATEGORY_3</th>\n",
       "      <th>CATEGORY_4</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>BARCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Sexual Health</td>\n",
       "      <td>Conductivity Gels &amp; Lotions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>796494407820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>Puffed Snacks</td>\n",
       "      <td>Cheese Curls &amp; Puffs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>023278011028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Hair Care</td>\n",
       "      <td>Hair Care Accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PLACEHOLDER MANUFACTURER</td>\n",
       "      <td>ELECSOP</td>\n",
       "      <td>461817824225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Oral Care</td>\n",
       "      <td>Toothpaste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLGATE-PALMOLIVE</td>\n",
       "      <td>COLGATE</td>\n",
       "      <td>035000466815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Medicines &amp; Treatments</td>\n",
       "      <td>Essential Oils</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...</td>\n",
       "      <td>MAPLE HOLISTICS</td>\n",
       "      <td>0806810850459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CATEGORY_1              CATEGORY_2                   CATEGORY_3  \\\n",
       "0  Health & Wellness           Sexual Health  Conductivity Gels & Lotions   \n",
       "1             Snacks           Puffed Snacks         Cheese Curls & Puffs   \n",
       "2  Health & Wellness               Hair Care        Hair Care Accessories   \n",
       "3  Health & Wellness               Oral Care                   Toothpaste   \n",
       "4  Health & Wellness  Medicines & Treatments               Essential Oils   \n",
       "\n",
       "  CATEGORY_4                                       MANUFACTURER  \\\n",
       "0        NaN                                                NaN   \n",
       "1        NaN                                                NaN   \n",
       "2        NaN                           PLACEHOLDER MANUFACTURER   \n",
       "3        NaN                                  COLGATE-PALMOLIVE   \n",
       "4        NaN  MAPLE HOLISTICS AND HONEYDEW PRODUCTS INTERCHA...   \n",
       "\n",
       "             BRAND        BARCODE  \n",
       "0              NaN   796494407820  \n",
       "1              NaN   023278011028  \n",
       "2          ELECSOP   461817824225  \n",
       "3          COLGATE   035000466815  \n",
       "4  MAPLE HOLISTICS  0806810850459  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Products Dataset:\")\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbf973-5ef5-4a41-9b5c-707a14442e29",
   "metadata": {},
   "source": [
    "# Step 3: Inspect and Define Data Types\n",
    "This step will both retrieve the column names and data types, and also define/standardize the correct data types based on observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "04f42d1d-371c-4423-8388-40e8ce7b2fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Users Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   ID            100000 non-null  object\n",
      " 1   CREATED_DATE  100000 non-null  object\n",
      " 2   BIRTH_DATE    96325 non-null   object\n",
      " 3   STATE         95188 non-null   object\n",
      " 4   LANGUAGE      69492 non-null   object\n",
      " 5   GENDER        94108 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUsers Dataset Info:\")\n",
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e301a981-6ee1-4607-86ff-761997fd0015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transactions Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   RECEIPT_ID      50000 non-null  object \n",
      " 1   PURCHASE_DATE   50000 non-null  object \n",
      " 2   SCAN_DATE       50000 non-null  object \n",
      " 3   STORE_NAME      50000 non-null  object \n",
      " 4   USER_ID         50000 non-null  object \n",
      " 5   BARCODE         44238 non-null  object \n",
      " 6   FINAL_QUANTITY  50000 non-null  object \n",
      " 7   FINAL_SALE      37500 non-null  float64\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTransactions Dataset Info:\")\n",
    "transactions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e546acbf-9d69-4f8f-b52b-90bea7b7587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Products Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 845552 entries, 0 to 845551\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   CATEGORY_1    845441 non-null  object\n",
      " 1   CATEGORY_2    844128 non-null  object\n",
      " 2   CATEGORY_3    784986 non-null  object\n",
      " 3   CATEGORY_4    67459 non-null   object\n",
      " 4   MANUFACTURER  619078 non-null  object\n",
      " 5   BRAND         619080 non-null  object\n",
      " 6   BARCODE       841527 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 45.2+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProducts Dataset Info:\")\n",
    "products_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ca8d19eb-000e-413d-bd59-95ff98857cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Defining Data Types\n",
    "# Define data types for Users dataset\n",
    "users_df['ID'] = users_df['ID'].astype('string')\n",
    "users_df['CREATED_DATE'] = pd.to_datetime(users_df['CREATED_DATE'], errors='coerce')\n",
    "users_df['BIRTH_DATE'] = pd.to_datetime(users_df['BIRTH_DATE'], errors='coerce')\n",
    "users_df['STATE'] = users_df['STATE'].astype('string')\n",
    "users_df['LANGUAGE'] = users_df['LANGUAGE'].astype('string')\n",
    "users_df['GENDER'] = users_df['GENDER'].astype('string')\n",
    "\n",
    "# Define data types for Transactions dataset\n",
    "transactions_df['RECEIPT_ID'] = transactions_df['RECEIPT_ID'].astype('string')\n",
    "transactions_df['PURCHASE_DATE'] = pd.to_datetime(transactions_df['PURCHASE_DATE'], errors='coerce')\n",
    "transactions_df['SCAN_DATE'] = pd.to_datetime(transactions_df['SCAN_DATE'], errors='coerce')\n",
    "transactions_df['STORE_NAME'] = transactions_df['STORE_NAME'].astype('string')\n",
    "transactions_df['USER_ID'] = transactions_df['USER_ID'].astype('string')\n",
    "transactions_df['BARCODE'] = transactions_df['BARCODE'].astype('string')\n",
    "transactions_df['FINAL_SALE'] = transactions_df['FINAL_SALE'].astype('float64')\n",
    "# Replace 'zero' with 0 in FINAL_QUANTITY and then convert to float64\n",
    "transactions_df['FINAL_QUANTITY'] = transactions_df['FINAL_QUANTITY'].replace('zero', 0)\n",
    "transactions_df['FINAL_QUANTITY'] = pd.to_numeric(transactions_df['FINAL_QUANTITY'], errors='coerce')\n",
    "\n",
    "# Define data types for Products dataset\n",
    "products_df['CATEGORY_1'] = products_df['CATEGORY_1'].astype('string')\n",
    "products_df['CATEGORY_2'] = products_df['CATEGORY_2'].astype('string')\n",
    "products_df['CATEGORY_3'] = products_df['CATEGORY_3'].astype('string')\n",
    "products_df['CATEGORY_4'] = products_df['CATEGORY_4'].astype('string')\n",
    "products_df['MANUFACTURER'] = products_df['MANUFACTURER'].astype('string')\n",
    "products_df['BRAND'] = products_df['BRAND'].astype('string')\n",
    "products_df['BARCODE'] = products_df['BARCODE'].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409987ab-2246-4b2b-8f68-86aedd33d605",
   "metadata": {},
   "source": [
    "# Step 4: Check for missing values in each dataset\n",
    "\n",
    "I will calculate the percentage of missing values for each column in the datasets. This helps identify columns with a high proportion of missing data, which may need to be addressed during data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fd01bdd3-1b87-47de-9169-ea7f23e528f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID               0.000\n",
       "CREATED_DATE     0.000\n",
       "BIRTH_DATE       3.675\n",
       "STATE            4.812\n",
       "LANGUAGE        30.508\n",
       "GENDER           5.892\n",
       "dtype: float64"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Users Missing Values:\")\n",
    "users_df.isnull().sum() / len(users_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3bead-a962-438f-bfbf-d2fcdd1f405c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__Summary of Missing Data in the Users Dataset__\n",
    "1. BIRTH_DATE:\n",
    "- 3.68% of the entries are missing.\n",
    "- This may affect age-related analyses if the missing values are not addressed.\n",
    "2. STATE:\n",
    "- 4.81% of the entries are missing.\n",
    "- This could impact regional analysis or segmentation of users by location.\n",
    "3. LANGUAGE:\n",
    "- A significant 30.51% of the entries are missing.\n",
    "- This large percentage may make it difficult to analyze user preferences based on language.\n",
    "4. GENDER:\n",
    "- 5.89% of the entries are missing.\n",
    "- Missing gender data could affect demographic segmentation.\n",
    "5. ID and CREATED_DATE:\n",
    "- Both columns have complete data with no missing values, which ensures that unique user identification and account creation dates are reliable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "25fa4cbe-4e39-485e-ad94-a886068576da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RECEIPT_ID         0.000\n",
       "PURCHASE_DATE      0.000\n",
       "SCAN_DATE          0.000\n",
       "STORE_NAME         0.000\n",
       "USER_ID            0.000\n",
       "BARCODE           11.524\n",
       "FINAL_QUANTITY     0.000\n",
       "FINAL_SALE        25.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Transactions Missing Values:\")\n",
    "transactions_df.isnull().sum() / len(transactions_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9475c-cf59-4da1-9e89-f08cbb73043d",
   "metadata": {},
   "source": [
    "__Summary of Missing Data in the Transactions Dataset__\n",
    "1. BARCODE:\n",
    "- 11.52% of the entries are missing.\n",
    "- This poses a notable challenge since the BARCODE column is essential for linking transactions to specific products.\n",
    "- The absence of values in this column may limit detailed product-level analysis and hinder integration with the products dataset.\n",
    "2. Other Columns:\n",
    "- The columns RECEIPT_ID, PURCHASE_DATE, SCAN_DATE, STORE_NAME, and USER_ID have complete data with 0% missing values, ensuring consistency for transaction-level analyses, such as examining sales trends, user behaviors, and store performance.\n",
    "3. FINAL_QUANTITY and FINAL_SALE:\n",
    "- While FINAL_QUANTITY has no missing values, the FINAL_SALE column has 25% missing data after correcting its format to numeric.\n",
    "- These missing entries could impact revenue-related analysis and need to be addressed, either by imputation or exclusion, depending on business priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "2595a214-2cb3-456c-8e73-1babc50a31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CATEGORY_1       0.013128\n",
       "CATEGORY_2       0.168411\n",
       "CATEGORY_3       7.162895\n",
       "CATEGORY_4      92.021898\n",
       "MANUFACTURER    26.784160\n",
       "BRAND           26.783923\n",
       "BARCODE          0.476020\n",
       "dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Products Missing Values:\")\n",
    "products_df.isnull().sum() / len(products_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d882a6d-0f03-4e63-8675-44735f21b3c7",
   "metadata": {},
   "source": [
    "__Summary of Missing Data in the Products Dataset__\n",
    "1. CATEGORY_1 to CATEGORY_4:\n",
    "- Missing data percentages:\n",
    "CATEGORY_1: 0.01%\n",
    "CATEGORY_2: 0.17%\n",
    "CATEGORY_3: 7.16%\n",
    "CATEGORY_4: 92.02%\n",
    "- These columns represent a hierarchical structure of product categorization, starting from broader categories (CATEGORY_1) to increasingly detailed subcategories (CATEGORY_4).\n",
    "- The high missingness in CATEGORY_4 is expected, as not all products require deep levels of categorization. \n",
    "- This pattern reflects the natural structure of product data rather than a quality issue.\n",
    "2. MANUFACTURER and BRAND:\n",
    "- Both columns have approximately 26.78% missing values.\n",
    "- Missing data here may impact analyses involving brand-specific or manufacturer-specific insights. \n",
    "- It is essential to consider strategies such as imputing missing values for critical use cases or focusing analyses on non-missing data.\n",
    "3. BARCODE:\n",
    "- Missing data percentage: 0.48%.\n",
    "- BARCODE is critical for linking products with transactions. \n",
    "- Although the missing percentage is low, efforts should be made to ensure that missing values do not disrupt the integration of datasets or analyses at the product level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25d3c1-5588-4e80-9ed4-b970b5081f9b",
   "metadata": {},
   "source": [
    "# Step 5: Descriptive Statistics for Categorical and Other Columns\n",
    "I will generate descriptive statistics for all columns in the dataset, including counts, unique values, most frequent values, and their frequencies. This provides insights into the distribution of categorical data and helps identify any inconsistencies or anomalies that require further cleaning or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b38543e5-4e55-45f0-8ef7-a3101d5b7b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Users Dataset Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>GENDER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000</td>\n",
       "      <td>100000</td>\n",
       "      <td>96325</td>\n",
       "      <td>95188</td>\n",
       "      <td>69492</td>\n",
       "      <td>94108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>5ef3b4f17053ab141787697d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TX</td>\n",
       "      <td>en</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9028</td>\n",
       "      <td>63403</td>\n",
       "      <td>64240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-07 05:31:20.864859648+00:00</td>\n",
       "      <td>1984-09-02 02:39:04.710417920+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-04-18 23:14:55+00:00</td>\n",
       "      <td>1900-01-01 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-01 21:16:19+00:00</td>\n",
       "      <td>1974-03-04 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-03-07 01:03:37+00:00</td>\n",
       "      <td>1985-10-25 00:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-01-30 13:47:44.500000+00:00</td>\n",
       "      <td>1998-02-02 05:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-11 17:59:15+00:00</td>\n",
       "      <td>2022-04-03 07:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID                         CREATED_DATE  \\\n",
       "count                     100000                               100000   \n",
       "unique                    100000                                  NaN   \n",
       "top     5ef3b4f17053ab141787697d                                  NaN   \n",
       "freq                           1                                  NaN   \n",
       "mean                         NaN  2022-01-07 05:31:20.864859648+00:00   \n",
       "min                          NaN            2014-04-18 23:14:55+00:00   \n",
       "25%                          NaN            2020-12-01 21:16:19+00:00   \n",
       "50%                          NaN            2022-03-07 01:03:37+00:00   \n",
       "75%                          NaN     2023-01-30 13:47:44.500000+00:00   \n",
       "max                          NaN            2024-09-11 17:59:15+00:00   \n",
       "\n",
       "                                 BIRTH_DATE  STATE LANGUAGE  GENDER  \n",
       "count                                 96325  95188    69492   94108  \n",
       "unique                                  NaN     52        2      11  \n",
       "top                                     NaN     TX       en  female  \n",
       "freq                                    NaN   9028    63403   64240  \n",
       "mean    1984-09-02 02:39:04.710417920+00:00    NaN      NaN     NaN  \n",
       "min               1900-01-01 00:00:00+00:00    NaN      NaN     NaN  \n",
       "25%               1974-03-04 00:00:00+00:00    NaN      NaN     NaN  \n",
       "50%               1985-10-25 00:00:00+00:00    NaN      NaN     NaN  \n",
       "75%               1998-02-02 05:00:00+00:00    NaN      NaN     NaN  \n",
       "max               2022-04-03 07:00:00+00:00    NaN      NaN     NaN  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nUsers Dataset Summary Statistics:\")\n",
    "users_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0c895c-e212-4f7b-aec8-a838672918da",
   "metadata": {},
   "source": [
    "__The potential issues identified in the descriptive statistics of the users dataset:__\n",
    "1. Unrealistic Data\n",
    "- BIRTH_DATE:\n",
    "  - The minimum value 1900-01-01 is highly unrealistic, implying users aged 123 years or older.\n",
    "  - This is likely due to placeholder values or data entry errors and should be flagged for correction or exclusion.\n",
    "- CREATED_DATE:\n",
    "  - The range of values (2014 to 2024) appears reasonable and aligns with expected account creation timelines.\n",
    "2. Inconsistent Categories\n",
    "- GENDER:\n",
    "  - The column contains 11 unique categories, including not_listed, other, and prefer_not_to_say.\n",
    "  - These categories may overlap or lack clear differentiation, making analysis more complex.\n",
    "  - Logical grouping of similar categories (e.g., combining into broader groups) is recommended to streamline analysis.\n",
    "3. Frequency Issues\n",
    "- STATE:\n",
    "  - The state TX has a disproportionately high frequency, with 9,028 entries.\n",
    "  - This could indicate an uneven geographic distribution or sampling bias.\n",
    "  - Further investigation is necessary to understand if this represents the actual data distribution or a collection anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b41e69aa-c983-4d07-af95-88f14f207e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transactions Dataset Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECEIPT_ID</th>\n",
       "      <th>PURCHASE_DATE</th>\n",
       "      <th>SCAN_DATE</th>\n",
       "      <th>STORE_NAME</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>BARCODE</th>\n",
       "      <th>FINAL_QUANTITY</th>\n",
       "      <th>FINAL_SALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>44238</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>37500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>24440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>954</td>\n",
       "      <td>17694</td>\n",
       "      <td>11028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>bedac253-2256-461b-96af-267748e6cecf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>64e62de5ca929250373e6cf5</td>\n",
       "      <td>078742223759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21326</td>\n",
       "      <td>22</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-24 09:44:17.664000</td>\n",
       "      <td>2024-07-27 00:29:55.204816896+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814427</td>\n",
       "      <td>4.576384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-06-12 00:00:00</td>\n",
       "      <td>2024-06-12 06:36:34.910000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-03 00:00:00</td>\n",
       "      <td>2024-07-05 10:59:32.364750080+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-24 00:00:00</td>\n",
       "      <td>2024-07-26 11:43:59.964499968+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-08-15 00:00:00</td>\n",
       "      <td>2024-08-17 17:10:10.855000064+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-09-08 00:00:00</td>\n",
       "      <td>2024-09-08 23:07:19.836000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>462.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.841794</td>\n",
       "      <td>6.625663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  RECEIPT_ID               PURCHASE_DATE  \\\n",
       "count                                  50000                       50000   \n",
       "unique                                 24440                         NaN   \n",
       "top     bedac253-2256-461b-96af-267748e6cecf                         NaN   \n",
       "freq                                      12                         NaN   \n",
       "mean                                     NaN  2024-07-24 09:44:17.664000   \n",
       "min                                      NaN         2024-06-12 00:00:00   \n",
       "25%                                      NaN         2024-07-03 00:00:00   \n",
       "50%                                      NaN         2024-07-24 00:00:00   \n",
       "75%                                      NaN         2024-08-15 00:00:00   \n",
       "max                                      NaN         2024-09-08 00:00:00   \n",
       "std                                      NaN                         NaN   \n",
       "\n",
       "                                  SCAN_DATE STORE_NAME  \\\n",
       "count                                 50000      50000   \n",
       "unique                                  NaN        954   \n",
       "top                                     NaN    WALMART   \n",
       "freq                                    NaN      21326   \n",
       "mean    2024-07-27 00:29:55.204816896+00:00        NaN   \n",
       "min        2024-06-12 06:36:34.910000+00:00        NaN   \n",
       "25%     2024-07-05 10:59:32.364750080+00:00        NaN   \n",
       "50%     2024-07-26 11:43:59.964499968+00:00        NaN   \n",
       "75%     2024-08-17 17:10:10.855000064+00:00        NaN   \n",
       "max        2024-09-08 23:07:19.836000+00:00        NaN   \n",
       "std                                     NaN        NaN   \n",
       "\n",
       "                         USER_ID       BARCODE  FINAL_QUANTITY    FINAL_SALE  \n",
       "count                      50000         44238    50000.000000  37500.000000  \n",
       "unique                     17694         11028             NaN           NaN  \n",
       "top     64e62de5ca929250373e6cf5  078742223759             NaN           NaN  \n",
       "freq                          22           182             NaN           NaN  \n",
       "mean                         NaN           NaN        0.814427      4.576384  \n",
       "min                          NaN           NaN        0.000000      0.000000  \n",
       "25%                          NaN           NaN        0.007500      1.790000  \n",
       "50%                          NaN           NaN        1.000000      3.000000  \n",
       "75%                          NaN           NaN        1.000000      5.190000  \n",
       "max                          NaN           NaN      276.000000    462.820000  \n",
       "std                          NaN           NaN        1.841794      6.625663  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nTransactions Dataset Summary Statistics:\")\n",
    "transactions_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dcedfb-3225-4a59-a5a2-1a35bf6320fe",
   "metadata": {},
   "source": [
    "__The potential issues identified in the descriptive statistics of the transaction dataset:__\n",
    "1. Missing Values (NaN):\n",
    "- BARCODE: Approximately 11.5% of the BARCODE column contains missing values. Since this column is critical for product identification, these missing entries may affect analyses or integrations that rely on product-level data.\n",
    "- FINAL_SALE: Around 25% of the FINAL_SALE column contains missing values. This could significantly impact revenue-related analyses, as these rows lack information about transaction totals.\n",
    "2. Issues with USER_ID and RECEIPT_ID:\n",
    "- USER_ID:\n",
    "  - The dataset contains 50,000 rows but only 17,694 unique USER_ID values. This suggests that some users have multiple transactions, which is expected for repeat customers. However, this may lead to potential bias in user-level analyses unless handled appropriately.\n",
    "- RECEIPT_ID:\n",
    "  - Only 24,440 unique RECEIPT_ID values exist in the dataset, despite 50,000 rows. This indicates that many receipt IDs are duplicated, which might suggest:\n",
    "  - Errors in the data entry or duplication of transactions.\n",
    "  - Bulk purchases recorded under the same receipt ID.\n",
    "  - Transactions split into multiple rows for the same receipt.\n",
    "This requires further investigation to understand whether the duplication is intentional or a data quality issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4a0de7de-d221-4a5a-bd56-8bd97093178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Products Dataset Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY_1</th>\n",
       "      <th>CATEGORY_2</th>\n",
       "      <th>CATEGORY_3</th>\n",
       "      <th>CATEGORY_4</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>BRAND</th>\n",
       "      <th>BARCODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>845441</td>\n",
       "      <td>844128</td>\n",
       "      <td>784986</td>\n",
       "      <td>67459</td>\n",
       "      <td>619078</td>\n",
       "      <td>619080</td>\n",
       "      <td>841527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27</td>\n",
       "      <td>121</td>\n",
       "      <td>344</td>\n",
       "      <td>127</td>\n",
       "      <td>4354</td>\n",
       "      <td>8122</td>\n",
       "      <td>841525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Health &amp; Wellness</td>\n",
       "      <td>Candy</td>\n",
       "      <td>Confection Candy</td>\n",
       "      <td>Lip Balms</td>\n",
       "      <td>PLACEHOLDER MANUFACTURER</td>\n",
       "      <td>REM BRAND</td>\n",
       "      <td>017000329260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>512695</td>\n",
       "      <td>121036</td>\n",
       "      <td>56965</td>\n",
       "      <td>9737</td>\n",
       "      <td>86902</td>\n",
       "      <td>20813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CATEGORY_1 CATEGORY_2        CATEGORY_3 CATEGORY_4  \\\n",
       "count              845441     844128            784986      67459   \n",
       "unique                 27        121               344        127   \n",
       "top     Health & Wellness      Candy  Confection Candy  Lip Balms   \n",
       "freq               512695     121036             56965       9737   \n",
       "\n",
       "                    MANUFACTURER      BRAND       BARCODE  \n",
       "count                     619078     619080        841527  \n",
       "unique                      4354       8122        841525  \n",
       "top     PLACEHOLDER MANUFACTURER  REM BRAND  017000329260  \n",
       "freq                       86902      20813             2  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nProducts Dataset Summary Statistics:\")\n",
    "products_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad5067-00e9-41cc-b591-043f191d499c",
   "metadata": {},
   "source": [
    "__The potential issues in the products dataset:__\n",
    "1. Incomplete Data Across Categories\n",
    "\n",
    "- CATEGORY_2, CATEGORY_3, CATEGORY_4:\n",
    "The number of entries decreases significantly from CATEGORY_2 (844,128) to CATEGORY_4 (67,459).\n",
    "- This reflects a hierarchical structure where deeper categorizations may not apply to all products. While this is expected, it should be validated to ensure consistent and accurate data representation.\n",
    "2. High Frequency in Specific Categories\n",
    "- CATEGORY_1:\n",
    "The \"Health & Wellness\" category contains 512,695 entries, dominating the dataset. This unbalanced distribution could introduce bias into the analysis or insights derived from the data.\n",
    "3. High Variability in Categorical Data\n",
    "- CATEGORY_3 and CATEGORY_4:\n",
    "CATEGORY_3 has 344 unique values, and CATEGORY_4 has 127 unique values. This high variability may complicate grouping, aggregation, or analysis, requiring careful categorization or feature engineering.\n",
    "4. Irregularities in Barcodes\n",
    "\n",
    "- Duplicate Barcodes:\n",
    "Among 841,527 total entries, only 841,342 barcodes are unique, indicating some duplicates.\n",
    "Potential problems with these duplicates include:\n",
    "  - Data entry errors or placeholder values.\n",
    "  - Multiple records representing the same product in different contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fd4e2-86b1-4de6-b0eb-bd5f83357e28",
   "metadata": {},
   "source": [
    "# Step 6: Check for duplicates in each dataset\n",
    "I will check each dataset for duplicate rows, as these can affect the accuracy of analysis and may need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3f97cb35-805c-4904-8316-8b4b08a6284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Rows Analysis:\n",
      "Users duplicate rows: 0\n",
      "Transactions duplicate rows: 171\n",
      "Products duplicate rows: 57\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDuplicate Rows Analysis:\")\n",
    "print(f\"Users duplicate rows: {users_df.duplicated().sum()}\")\n",
    "print(f\"Transactions duplicate rows: {transactions_df.duplicated().sum()}\")\n",
    "print(f\"Products duplicate rows: {products_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "37c5dfdb-b917-4000-b358-3ca1534f7084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                RECEIPT_ID PURCHASE_DATE  \\\n",
      "2724  1c12bd8a-c68c-41ee-a26d-294021d3e0b8    2024-09-07   \n",
      "4192  2acd7e8d-37df-4e51-8ee5-9a9c8c1d9711    2024-09-08   \n",
      "6572  431fe612-ed55-470e-939c-043ad31f33f3    2024-09-07   \n",
      "6623  43955b35-6fbc-4909-a4de-1a0de0dc387f    2024-09-06   \n",
      "7675  4ec870d2-c39f-4a40-bf8a-26a079409b20    2024-09-08   \n",
      "\n",
      "                            SCAN_DATE            STORE_NAME  \\\n",
      "2724 2024-09-07 15:44:35.241000+00:00                   CVS   \n",
      "4192 2024-09-08 11:13:01.935000+00:00               WALMART   \n",
      "6572 2024-09-07 16:39:01.409000+00:00  DOLLAR GENERAL STORE   \n",
      "6623 2024-09-08 18:32:30.031000+00:00               WALMART   \n",
      "7675 2024-09-08 19:39:01.589000+00:00               WALMART   \n",
      "\n",
      "                       USER_ID       BARCODE  FINAL_QUANTITY  FINAL_SALE  \n",
      "2724  65af09757050d0a6206ab136          <NA>             1.0         NaN  \n",
      "4192  663140f9b7b24d45d938f3be  024000048336             1.0         NaN  \n",
      "6572  5e038cebcb322c11de193bb7  012000504051             1.0         NaN  \n",
      "6623  625364ddda4fb11c8a9fcb85  371687660147             0.0       12.97  \n",
      "7675  638e9ae602a4e512e0585b59  072392016358             0.0        1.48  \n",
      "               CATEGORY_1   CATEGORY_2           CATEGORY_3 CATEGORY_4  \\\n",
      "91710   Health & Wellness    Skin Care                 <NA>       <NA>   \n",
      "109639         Restaurant    Beverages                 Soda  Diet Soda   \n",
      "126613         Restaurant    Beverages                 Soda       <NA>   \n",
      "128662             Snacks  Snack Cakes  Brownie Snack Cakes       <NA>   \n",
      "136757         Restaurant    Beverages                 Soda       <NA>   \n",
      "\n",
      "                 MANUFACTURER                          BRAND BARCODE  \n",
      "91710        BEIERSDORF, INC.                     COPPERTONE    <NA>  \n",
      "109639                PEPSICO                          PEPSI    <NA>  \n",
      "126613                PEPSICO                          PEPSI    <NA>  \n",
      "128662                  BIMBO  ENTENMANN'S SWEET BAKED GOODS    <NA>  \n",
      "136757  THE COCA-COLA COMPANY                      COCA-COLA    <NA>  \n"
     ]
    }
   ],
   "source": [
    "duplicates_transactions = transactions_df[transactions_df.duplicated()]\n",
    "print(duplicates_transactions.head())\n",
    "duplicates_products = products_df[products_df.duplicated()]\n",
    "print(duplicates_products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b5f49b-d732-461e-b83b-6d92ec130b6c",
   "metadata": {},
   "source": [
    "# Step 7: Clean Data for EDA Preparation\n",
    "In this step, I address and resolve the data quality issues identified earlier, including handling duplicate rows, correcting inconsistent values, and ensuring logical integrity in the dataset. These cleaning actions aim to prepare the data for effective exploratory data analysis (EDA) by ensuring its accuracy and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5465c3d-e4cc-48ee-9014-51b6af27b1d0",
   "metadata": {},
   "source": [
    "__Filter out rows where the 'BARCODE' column has missing values__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de4b6f-ca83-4594-a3f4-9c9945fae944",
   "metadata": {},
   "source": [
    "I deleted the product and transaction records with null values in the BARCODE field because it serves as a link to the transaction data. Without a BARCODE, those records are not useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "65aceb25-3262-4612-a432-8642674ae4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows in products_df: 841527\n",
      "Products duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "products_df = products_df[products_df['BARCODE'].notnull()]\n",
    "print(f\"Remaining rows in products_df: {len(products_df)}\")\n",
    "# Check the duplicate dataset\n",
    "print(f\"Products duplicate rows: {products_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d43a7ee7-12ad-4b27-8bfb-85cff1eb37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows in transactions_df: 44238\n"
     ]
    }
   ],
   "source": [
    "transactions_df = transactions_df[transactions_df['BARCODE'].notnull()]\n",
    "print(f\"Remaining rows in transactions_df: {len(transactions_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a708d0d-0c02-4593-a589-f4f0548173ca",
   "metadata": {},
   "source": [
    "This step ensures only products with valid barcodes remain, as the 'BARCODE' is used to connect to the transactions table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183dcf10-92ad-4e80-8a6c-f0a6975be5bc",
   "metadata": {},
   "source": [
    "__Removing Incomplete and Duplicate Transactions__\n",
    "\n",
    "This section filters out rows where either FINAL_QUANTITY or FINAL_SALE is missing or zero, ensuring the dataset retains only valid transaction records. Duplicate RECEIPT_ID entries are also removed, keeping only the first occurrence to maintain data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bb7f5ad2-384e-46ac-b793-3b8ed860b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to remove rows where FINAL_QUANTITY or FINAL_SALE is 0 or blank\n",
    "transactions_df = transactions_df[\n",
    "    (transactions_df['FINAL_QUANTITY'] != 0) & \n",
    "    (transactions_df['FINAL_SALE'] != 0)\n",
    "]\n",
    "\n",
    "# Drop duplicate RECEIPT_ID while keeping the first occurrence (or last depending on preference)\n",
    "transactions_df = transactions_df.sort_values(by=['FINAL_SALE'], ascending=False)\n",
    "transactions_df = transactions_df.drop_duplicates(subset=['RECEIPT_ID'], keep='first')\n",
    "\n",
    "# Check the resulting dataset\n",
    "print(f\"Transactions duplicate rows: {transactions_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608244bb-b171-4353-a2fa-311be99edeb5",
   "metadata": {},
   "source": [
    "In the transactions dataset, I identified that some BARCODE values were \"-1\", which is not logical for barcodes. Therefore, I removed these invalid values by setting them to empty strings to ensure the integrity of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c6ae3253-6693-40d4-951e-ec51c3b94e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the BARCODE column is treated as a string\n",
    "transactions_df['BARCODE'] = transactions_df['BARCODE'].astype(str)\n",
    "\n",
    "# Replace '-1' with an empty string\n",
    "transactions_df['BARCODE'] = transactions_df['BARCODE'].apply(lambda x: '' if x == '-1' else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ca4f4-8984-45b9-a901-2ecba85be8cd",
   "metadata": {},
   "source": [
    "__Cleaning and Standardizing the GENDER Column__\n",
    "\n",
    "This section involves defining a mapping function to clean and standardize the values in the GENDER column, addressing inconsistencies, handling missing values, and grouping less common responses into a logical framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "29052f25-81ee-4696-8f3e-890d4fa5cae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                'female',                     <NA>,                   'male',\n",
       "             'non_binary',            'transgender',      'prefer_not_to_say',\n",
       "             'not_listed',             'Non-Binary',                'unknown',\n",
       "          'not_specified', \"My gender isn't listed\",      'Prefer not to say']\n",
       "Length: 12, dtype: string"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display all unique values in the GENDER column\n",
    "users_df['GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e356b6ac-9332-404c-bc9f-e71fee537085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENDER\n",
      "female               64240\n",
      "male                 25829\n",
      "other                 6116\n",
      "transgender           1772\n",
      "prefer_not_to_say     1351\n",
      "non_binary             507\n",
      "not_listed             185\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define a mapping function for cleaning the GENDER column\n",
    "def clean_gender(gender):\n",
    "    if pd.isnull(gender):\n",
    "        return 'other'  # Treat NaN as 'other'\n",
    "    gender = gender.lower().strip()\n",
    "    if gender in ['female']:\n",
    "        return 'female'\n",
    "    elif gender in ['male']:\n",
    "        return 'male'\n",
    "    elif gender in ['non_binary', 'non-binary']:\n",
    "        return 'non_binary'\n",
    "    elif gender in ['prefer_not_to_say', 'prefer not to say']:\n",
    "        return 'prefer_not_to_say'\n",
    "    elif gender in ['transgender']:\n",
    "        return 'transgender'\n",
    "    elif gender in ['not_listed', \"my gender isn't listed\"]:\n",
    "        return 'not_listed'\n",
    "    elif gender in ['not_specified', 'unknown']:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return 'other'  # Default to 'other' for any unexpected values\n",
    "\n",
    "# Apply the mapping function and replace the GENDER column\n",
    "users_df['GENDER'] = users_df['GENDER'].apply(clean_gender)\n",
    "\n",
    "# Display the unique values in the updated GENDER column\n",
    "print(users_df['GENDER'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188535f-dcd8-49d1-9c02-c602f91af60e",
   "metadata": {},
   "source": [
    "__The GENDER column was cleaned and consolidated to simplify analysis while maintaining logical distinctions.__\n",
    "\n",
    "Heres the explanation:\n",
    "- Purpose: Reduce the number of unique values for easier interpretation and processing.\n",
    "- Why Keep not_listed:\n",
    "  It reflects users indicating their identity wasnt included in the options, which differs from ambiguous entries like unknown.\n",
    "- Why Group into other:\n",
    "  - Ambiguity: Terms like not_specified and unknown dont indicate any clear gender identity but rather imply missing or incomplete information. Grouping these into other avoids overcomplicating the dataset while maintaining logical consistency.\n",
    "  - Practicality: These terms dont provide actionable insights individually, so grouping them ensures clarity without diminishing analytical value.\n",
    "- Final Categories:\n",
    "  - female and male: Standard binary categories.\n",
    "  - non_binary and transgender: Preserved for inclusivity.\n",
    "  - not_listed: Retained to reflect users who felt their gender wasnt represented.\n",
    "  - prefer_not_to_say: Indicates intentional non-disclosure.\n",
    "  - other: Includes ambiguous or undefined entries like unknown, not_specified, and NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81249588-c8b2-4fea-8d5f-b11877c179c6",
   "metadata": {},
   "source": [
    "__Filter Out Rows with Unreasonable Ages__\n",
    "\n",
    "I defined a reasonable age as below 100 for this project. In a formal project, this criteria would be confirmed with the responsible personnel to ensure alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "6f7d069d-f9f9-42d5-bddd-fbee6a73c958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_DATE</th>\n",
       "      <th>BIRTH_DATE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>UNREASONABLE_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>62be5974baa38d1a1f6b6725</td>\n",
       "      <td>2022-07-01 02:18:28+00:00</td>\n",
       "      <td>1903-01-01 05:00:00+00:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>male</td>\n",
       "      <td>122.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>5f20a5a2b06a3214c6db4811</td>\n",
       "      <td>2020-07-28 22:24:34+00:00</td>\n",
       "      <td>1923-07-28 04:00:00+00:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>transgender</td>\n",
       "      <td>101.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>60ac6acc79ed9200a6ebc24a</td>\n",
       "      <td>2021-05-25 03:11:08+00:00</td>\n",
       "      <td>1901-05-25 00:00:00+00:00</td>\n",
       "      <td>UT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>female</td>\n",
       "      <td>123.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6499</th>\n",
       "      <td>60a6e4af3369535cb6c4c89d</td>\n",
       "      <td>2021-05-20 22:37:35+00:00</td>\n",
       "      <td>1901-10-13 00:00:00+00:00</td>\n",
       "      <td>CA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>male</td>\n",
       "      <td>123.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7723</th>\n",
       "      <td>624501294eadbb0ccddf2cc6</td>\n",
       "      <td>2022-03-31 01:17:29+00:00</td>\n",
       "      <td>1922-12-22 00:00:00+00:00</td>\n",
       "      <td>IL</td>\n",
       "      <td>es-419</td>\n",
       "      <td>male</td>\n",
       "      <td>102.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96783</th>\n",
       "      <td>5ee14ae9e7bf80140949615c</td>\n",
       "      <td>2020-06-10 21:04:43+00:00</td>\n",
       "      <td>1907-11-13 06:00:00+00:00</td>\n",
       "      <td>LA</td>\n",
       "      <td>en</td>\n",
       "      <td>male</td>\n",
       "      <td>117.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98338</th>\n",
       "      <td>6418e8d1197cb65cc272db79</td>\n",
       "      <td>2023-03-20 23:14:25+00:00</td>\n",
       "      <td>1906-01-01 06:00:00+00:00</td>\n",
       "      <td>TN</td>\n",
       "      <td>en</td>\n",
       "      <td>male</td>\n",
       "      <td>119.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98639</th>\n",
       "      <td>61a1127207acef7276e6158f</td>\n",
       "      <td>2021-11-26 16:59:30+00:00</td>\n",
       "      <td>1901-01-01 05:00:00+00:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>en</td>\n",
       "      <td>male</td>\n",
       "      <td>124.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98847</th>\n",
       "      <td>60bc0f11a3100c10461d86fa</td>\n",
       "      <td>2021-06-05 23:56:01+00:00</td>\n",
       "      <td>1901-01-01 05:00:00+00:00</td>\n",
       "      <td>NY</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>female</td>\n",
       "      <td>124.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98873</th>\n",
       "      <td>5ca8bf5c5f04d512fc5d3dc6</td>\n",
       "      <td>2019-04-06 15:01:48+00:00</td>\n",
       "      <td>1917-12-07 00:00:00+00:00</td>\n",
       "      <td>PA</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>female</td>\n",
       "      <td>107.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             ID              CREATED_DATE  \\\n",
       "3656   62be5974baa38d1a1f6b6725 2022-07-01 02:18:28+00:00   \n",
       "5190   5f20a5a2b06a3214c6db4811 2020-07-28 22:24:34+00:00   \n",
       "5878   60ac6acc79ed9200a6ebc24a 2021-05-25 03:11:08+00:00   \n",
       "6499   60a6e4af3369535cb6c4c89d 2021-05-20 22:37:35+00:00   \n",
       "7723   624501294eadbb0ccddf2cc6 2022-03-31 01:17:29+00:00   \n",
       "...                         ...                       ...   \n",
       "96783  5ee14ae9e7bf80140949615c 2020-06-10 21:04:43+00:00   \n",
       "98338  6418e8d1197cb65cc272db79 2023-03-20 23:14:25+00:00   \n",
       "98639  61a1127207acef7276e6158f 2021-11-26 16:59:30+00:00   \n",
       "98847  60bc0f11a3100c10461d86fa 2021-06-05 23:56:01+00:00   \n",
       "98873  5ca8bf5c5f04d512fc5d3dc6 2019-04-06 15:01:48+00:00   \n",
       "\n",
       "                     BIRTH_DATE STATE LANGUAGE       GENDER    AGE  \\\n",
       "3656  1903-01-01 05:00:00+00:00    PA       en         male  122.0   \n",
       "5190  1923-07-28 04:00:00+00:00    PA     <NA>  transgender  101.0   \n",
       "5878  1901-05-25 00:00:00+00:00    UT     <NA>       female  123.0   \n",
       "6499  1901-10-13 00:00:00+00:00    CA     <NA>         male  123.0   \n",
       "7723  1922-12-22 00:00:00+00:00    IL   es-419         male  102.0   \n",
       "...                         ...   ...      ...          ...    ...   \n",
       "96783 1907-11-13 06:00:00+00:00    LA       en         male  117.0   \n",
       "98338 1906-01-01 06:00:00+00:00    TN       en         male  119.0   \n",
       "98639 1901-01-01 05:00:00+00:00    PA       en         male  124.0   \n",
       "98847 1901-01-01 05:00:00+00:00    NY     <NA>       female  124.0   \n",
       "98873 1917-12-07 00:00:00+00:00    PA     <NA>       female  107.0   \n",
       "\n",
       "       UNREASONABLE_AGE  \n",
       "3656               True  \n",
       "5190               True  \n",
       "5878               True  \n",
       "6499               True  \n",
       "7723               True  \n",
       "...                 ...  \n",
       "96783              True  \n",
       "98338              True  \n",
       "98639              True  \n",
       "98847              True  \n",
       "98873              True  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate age\n",
    "today = datetime.today()\n",
    "users_df['AGE'] = users_df['BIRTH_DATE'].apply(\n",
    "    lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)) if pd.notnull(x) else None\n",
    ")\n",
    "# Check for unreasonable ages\n",
    "users_df['UNREASONABLE_AGE'] = users_df['AGE'].apply(\n",
    "    lambda x: x < 0 or x > 100 if x is not None else None\n",
    ")\n",
    "\n",
    "# Display rows with unreasonable ages\n",
    "UNREASONABLE_AGE = users_df[users_df['UNREASONABLE_AGE'] == True]\n",
    "UNREASONABLE_AGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29b136-9852-4f3b-b440-1aea86c86410",
   "metadata": {},
   "source": [
    "__Replace Unreasonable Ages with NaN__\n",
    "\n",
    "To maintain data integrity, I replaced rows with ages above the defined limit (100 years) with NaN for further analysis or review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2e6e6581-3266-4ed6-8649-f81efcc158fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace unreasonable ages with NaN\n",
    "users_df.loc[users_df['UNREASONABLE_AGE'], 'BIRTH_DATE'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c21a9de-a69c-4164-ae6a-4105348430c1",
   "metadata": {},
   "source": [
    "- I set the reasonable age range to 0-100 to account for living individuals, acknowledging that accounts for young children might be created by their guardians.\n",
    "- Ages over 100 are unlikely and often result from data entry errors.\n",
    "- I replaced unreasonable values with blanks rather than removing rows to preserve other valid data.\n",
    "- I recommend adding input validation during account registration, such as limiting birth year entry to a realistic range (e.g., 1920 to the current year)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfe5a53-8bff-49de-adc9-e0b78a1d1a75",
   "metadata": {},
   "source": [
    "__Standardize Date Format for Tableau Calculations__\n",
    "\n",
    "The CREATED_DATE and BIRTH_DATE columns were reformatted to the YYYY-MM-DD standard, making them suitable for calculations and compatibility with Tableau.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "d3a58830-0360-4b34-95ad-12f563db206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CREATED_DATE and BIRTH_DATE columns to datetime format and standardize to YYYY-MM-DD\n",
    "users_df['CREATED_DATE'] = pd.to_datetime(users_df['CREATED_DATE']).dt.strftime('%Y-%m-%d')\n",
    "users_df['BIRTH_DATE'] = pd.to_datetime(users_df['BIRTH_DATE']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "cd2a7984-6673-41cf-95c8-6721d83c305b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORY_1         111\n",
      "CATEGORY_2         661\n",
      "CATEGORY_3       58714\n",
      "CATEGORY_4      774291\n",
      "MANUFACTURER    226227\n",
      "BRAND           226225\n",
      "BARCODE              0\n",
      "dtype: int64\n",
      "ID                      0\n",
      "CREATED_DATE            0\n",
      "BIRTH_DATE           3736\n",
      "STATE                4812\n",
      "LANGUAGE            30508\n",
      "GENDER                  0\n",
      "AGE                  3675\n",
      "UNREASONABLE_AGE        0\n",
      "dtype: int64\n",
      "RECEIPT_ID         0\n",
      "PURCHASE_DATE      0\n",
      "SCAN_DATE          0\n",
      "STORE_NAME         0\n",
      "USER_ID            0\n",
      "BARCODE            0\n",
      "FINAL_QUANTITY     0\n",
      "FINAL_SALE        55\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# replace null to None\n",
    "products_df = products_df.where(pd.notnull(products_df), None)\n",
    "print(products_df.isnull().sum())\n",
    "users_df = users_df.where(pd.notnull(users_df), None)\n",
    "print(users_df.isnull().sum())\n",
    "transactions_df = transactions_df.where(pd.notnull(transactions_df), None)\n",
    "print(transactions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a3374-cf03-47af-a64d-3cb36b30018b",
   "metadata": {},
   "source": [
    "# Step 8: Save Cleaned Dataset to CSV\n",
    "To ensure my cleaned data is ready for visualization in Tableau, I will save the cleaned datasets as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "5b2492e4-7e0a-4444-bef2-596996b17f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "products_df.to_csv('/Users/jc/Desktop/xing/fetch/interview/cleaned_products_dataset.csv', index=False, encoding=\"utf-8\")\n",
    "transactions_df.to_csv('/Users/jc/Desktop/xing/fetch/interview/cleaned_transactions_dataset.csv', index=False, encoding=\"utf-8\")\n",
    "users_df.to_csv('/Users/jc/Desktop/xing/fetch/interview/cleaned_users_dataset.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf6cb3-1558-4b2f-9183-f7faab5126ee",
   "metadata": {},
   "source": [
    "# Summary of Data Quality Issues and Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3c983-b5da-4162-9278-720bbe93d427",
   "metadata": {},
   "source": [
    "__Are there any data quality issues present?__\n",
    "\n",
    "1. Missing Values:\n",
    "- Users Dataset:\n",
    "  - BIRTH_DATE: Approximately 3.68% of the values are missing, which could impact age-based analysis.\n",
    "  - STATE: About 4.81% of the values are missing, potentially affecting regional or geographic segmentation analysis.\n",
    "  - LANGUAGE: A significant 30.51% of the values are missing, which makes analyzing language preferences challenging.\n",
    "  - GENDER: Around 5.89% of the values are missing, which could affect demographic segmentation by gender.\n",
    "- Transactions Dataset:\n",
    "  - BARCODE: About 11.52% of the values are missing, hindering product-level analysis and integration with the products dataset.\n",
    "  - FINAL_SALE: Approximately 25% of the values are missing, which could impact revenue-related analysis.\n",
    "- Products Dataset:\n",
    "  - CATEGORY_4: A high missing rate of 92% reflects the hierarchical structure of categorization rather than a true data issue.\n",
    "  - MANUFACTURER and BRAND: Both have about 26.78% missing values, potentially impacting brand or manufacturer-specific analysis.\n",
    "  - BARCODE: Although the missing rate is only 0.48%, ensuring its accuracy is essential to avoid integration issues.\n",
    "\n",
    "2. Outliers:\n",
    "- Users Dataset:\n",
    "  - BIRTH_DATE: Contains unrealistic values such as January 1, 1900, implying users aged 120+ years. This likely indicates data entry errors.\n",
    "    - Solution: Implemented a reasonable age range (0100 years) and flagged unrealistic ages as NaN.\n",
    "- Transactions Dataset:\n",
    "  - FINAL_QUANTITY and FINAL_SALE: Contain 0 or blank values, which may indicate invalid transactions. These have been filtered out.\n",
    "\n",
    "3. Duplicate Records:\n",
    "- Transactions Dataset:\n",
    "  - Identified 171 duplicate RECEIPT_ID entries. After cleaning, the dataset has significantly fewer rows, ensuring consistency.\n",
    "- Products Dataset:\n",
    "  - Found 57 duplicate records. These rows lack barcodes and may represent the same product under different contexts.\n",
    "4. Inconsistent Categories:\n",
    "- Users Dataset:\n",
    "  - GENDER: Contains 11 unique values, including ambiguous categories such as not_listed and unknown. These values were cleaned and grouped into simplified categories (e.g., female, male, other).\n",
    "- Products Dataset:\n",
    "  - The number of unique values varies significantly across category levels. For instance, CATEGORY_1 has 27 categories, while CATEGORY_4 has only 127, reflecting the natural structure of hierarchical categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007d4365-8e63-4d62-a67a-86c2508fd338",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "__Are there any fields that are challenging to understand?__\n",
    "1. GENDER Field:\n",
    "- Contains uncommon or redundant values such as non_binary and Non-Binary, requiring further standardization.\n",
    "- The diversity in values complicates analysis, but grouping them into broader categories improves efficiency.\n",
    "2. BARCODE Field:\n",
    "- Missing or duplicate barcodes in the Products and Transactions datasets pose challenges for integration and product-level analysis.\n",
    "- Certain barcode values (e.g., -1) are illogical and require further cleaning.\n",
    "3. FINAL_SALE and FINAL_QUANTITY Fields:\n",
    "- Some transactions are difficult to interpret due to blank or invalid values.\n",
    "- Proper cleaning requires consultation with stakeholders to ensure alignment with business rules.\n",
    "- __FINAL_QUANTITY__, in particular, contains decimal values. Upon deeper inspection, the category corresponds to supermarkets, suggesting these could represent items sold by weight (e.g., produce or deli items). However, this assumption requires clarification, and these records have not been removed.\n",
    "4. CATEGORY_4 Field:\n",
    "- High missing rate (92%) suggests that many products lack deep-level categorization, limiting detailed product-level analysis.\n",
    "5. USER_ID and RECEIPT_ID:\n",
    "- USER_ID: Initially exhibited a many-to-one relationship with transactions (17,694 unique IDs for 50,000 transactions). After cleaning, the dataset has significantly fewer rows, reducing potential biases. However, this highlights the need to validate the cleaned data against expected business logic.\n",
    "- RECEIPT_ID: Repeated entries may indicate batch transactions or data entry errors. Further investigation is required.\n",
    "6. Challenge  Limited Transaction Data:\n",
    "- The Transactions dataset only includes data from June to August 2024, making it insufficient for long-term trend analysis or evaluating seasonal sales patterns.\n",
    "- Cleaning the data, such as handling duplicates, has further reduced the dataset size. These limitations restrict the ability to derive comprehensive insights into sales performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af9cc52-2e19-49ed-8dd0-14f03efebf46",
   "metadata": {},
   "source": [
    "# import into MYSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989e15d-8b98-4fbc-8ecb-0e7ad7c3f40d",
   "metadata": {},
   "source": [
    "import pymysql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c02d0-aa61-4f4d-978d-9b01a567f58c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#Connect to the MySQL database\n",
    "\n",
    "connection = pymysql.connect(\n",
    "        host='localhost',         \n",
    "        user='root',              \n",
    "        password='jasmine0418',   \n",
    "        database='fetch_db'       \n",
    "    )\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098195f8-527d-4a6c-af4f-e656eda5ca27",
   "metadata": {},
   "source": [
    "#Load the cleaned dataset \n",
    "\n",
    "csv_file_path = '/Users/jc/Desktop/xing/fetch/interview/cleaned_products_dataset.csv'\n",
    "df = pd.read_csv(csv_file_path, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f64eb-3c15-468f-a3b4-48707d347f33",
   "metadata": {},
   "source": [
    "#replace null to None\n",
    "\n",
    "df = df.where(pd.notnull(df), None)\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3966e-bbed-4c7f-ba48-c917fad810e5",
   "metadata": {},
   "source": [
    "for _, row in df.iterrows():\n",
    "    data = (\n",
    "        row['CATEGORY_1'],\n",
    "        row['CATEGORY_2'],\n",
    "        row['CATEGORY_3'],\n",
    "        row['CATEGORY_4'],\n",
    "        row['MANUFACTURER'],\n",
    "        row['BRAND'],\n",
    "        row['BARCODE']\n",
    "    )\n",
    "    print(data)  # Debug: Print data to verify each row's content\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO products (CATEGORY_1, CATEGORY_2, CATEGORY_3, CATEGORY_4, MANUFACTURER, BRAND, BARCODE) \n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", data)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360803d-4890-4c14-b016-5cbad5177f35",
   "metadata": {},
   "source": [
    "csv_file_path = '/Users/jc/Desktop/xing/fetch/interview/cleaned_transactions_dataset.csv'\n",
    "df2 = pd.read_csv(csv_file_path, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b926-4b93-469f-a6bc-a610af867241",
   "metadata": {},
   "source": [
    "#Replace null values and remove rows with missing BARCODE\n",
    "\n",
    "df2 = df2.where(pd.notnull(df2), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c68e2-5cae-4830-932f-227497540416",
   "metadata": {},
   "source": [
    "#Truncate the `transactions` table\n",
    "\n",
    "print(\"Truncating the transactions table...\")\n",
    "cursor.execute(\"TRUNCATE TABLE transactions;\")\n",
    "connection.commit()\n",
    "print(\"Transactions table truncated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172f3fc-0cca-4937-bc67-f564dc9e3a4b",
   "metadata": {},
   "source": [
    "#Insert the cleaned data\n",
    "\n",
    "print(\"Inserting cleaned data into transactions table...\")\n",
    "sql = \"\"\"\n",
    "    INSERT INTO transactions (RECEIPT_ID, PURCHASE_DATE, SCAN_DATE, STORE_NAME, USER_ID, BARCODE, FINAL_QUANTITY, FINAL_SALE)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "for _, row in df2.iterrows():\n",
    "    data = (\n",
    "        row['RECEIPT_ID'],\n",
    "        row['PURCHASE_DATE'],\n",
    "        row['SCAN_DATE'],\n",
    "        row['STORE_NAME'],\n",
    "        row['USER_ID'],\n",
    "        row['BARCODE'],\n",
    "        row['FINAL_QUANTITY'],\n",
    "        row['FINAL_SALE']\n",
    "    )\n",
    "    cursor.execute(sql, data)\n",
    "\n",
    "#Commit changes and close the connection\n",
    "\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e732dc-7e23-46a4-bc18-4972bebf0c3c",
   "metadata": {},
   "source": [
    "#Load the cleaned dataset\n",
    "\n",
    "csv_file_path = '/Users/jc/Desktop/xing/fetch/interview/cleaned_users_dataset.csv'\n",
    "df3 = pd.read_csv(csv_file_path, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5cd6a-edfc-474f-aa55-41f9d562f8b9",
   "metadata": {},
   "source": [
    "#Replace null values with None\n",
    "\n",
    "df3 = df3.where(pd.notnull(df3), None)\n",
    "print(f\"Total rows in cleaned DataFrame: {len(df3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb617ad-3c81-4d09-9a9f-9778770ed066",
   "metadata": {},
   "source": [
    "#Truncate the `users` table\n",
    "\n",
    "print(\"Truncating the users table...\")\n",
    "cursor.execute(\"TRUNCATE TABLE users;\")\n",
    "connection.commit()\n",
    "print(\"Users table truncated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1850ab-8f0f-4d2e-9921-60e5b7450501",
   "metadata": {},
   "source": [
    "#Insert the cleaned data into `users` table\n",
    "\n",
    "print(\"Inserting cleaned data into users table...\")\n",
    "sql = \"\"\"\n",
    "    INSERT INTO users (ID, CREATED_DATE, BIRTH_DATE, STATE, LANGUAGE, GENDER, AGE, UNREASONABLE_AGE)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "#Loop through the DataFrame and insert data\n",
    "\n",
    "for _, row in df3.iterrows():\n",
    "    data = (\n",
    "        row['ID'],\n",
    "        row['CREATED_DATE'],\n",
    "        row['BIRTH_DATE'],\n",
    "        row['STATE'],\n",
    "        row['LANGUAGE'],\n",
    "        row['GENDER'],\n",
    "        row['AGE'],\n",
    "        row['UNREASONABLE_AGE']\n",
    "    )\n",
    "    cursor.execute(sql, data)\n",
    "\n",
    "#Commit the changes\n",
    "\n",
    "connection.commit()\n",
    "print(\"Cleaned data inserted into users table successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794dcb3-f6e2-438f-81d8-4d976f36afa0",
   "metadata": {},
   "source": [
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
